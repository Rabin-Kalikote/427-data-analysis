---
title: "Ask Mattrab Note-Views Analysis" 
author: "Rabin Kumar Kalikote"
date: "2025-04-03"
editor: visual
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 2
    number-sections: true
    code-tools: true
    df-print: paged
    editor: visual
---

```{r setup, include=FALSE}
# load packages here
library(tidyverse)
library(tidymodels)
library(ISLR2)
library(ggplot2)
library(broom)
library(dplyr)
library(tidyr)
library(stringr)
library(forcats)
library(knitr)
library(ggrepel)
library(datasets)
library(kknn)

tidymodels_prefer()

# Add global options for cleaner output
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  out.width = "100%"
)
```

# Introduction

## Data: Ask Mattrab Note Views

The dataset used in this analysis was extracted from the database of the educational platform [Ask Mattrab](https://www.askmattrab.com). Ask Mattrab is a collaborative learning platform where users can create, share, and access educational notes. The platform allows users to publish notes on various subjects and grades, making it a valuable resource for students and educators.

### Dataset Description

The dataset contains 2,083 records, each representing a note published on the platform. The data includes the following features:

-   **id**: Primary key, a unique identifier for each note.
-   **title**: The title of the note, which users see before opening the note.
-   **body**: The number of characters in the content of the note. (The actual content is excluded for privacy and security reasons.)
-   **created_at**: The date when the note was created.
-   **updated_at**: The date when the note was last modified.
-   **user_id**: The ID of the user who created the note (foreign key).
-   **image_file_name**: The name of the thumbnail image associated with the note.
-   **image_content_type**: The type of the thumbnail image (e.g., JPEG, PNG).
-   **image_file_size**: The size of the thumbnail image in bytes.
-   **image_updated_at**: The date when the thumbnail image was last updated.
-   **view**: The total number of times the note was opened and read (target variable).
-   **is_verified**: A boolean indicating whether the note is verified for publication.
-   **status**: The publication status of the note (e.g., draft or published).
-   **grade_id**: The grade level (foreign key) to which the note belongs.
-   **subject_id**: The subject (foreign key) to which the note belongs.
-   **chapter_id**: The chapter (foreign key) to which the note belongs.
-   **position**: Indicates whether the note is visible in the Ask Mattrab library.

### Objective

The primary goal of this analysis is to build a predictive model to estimate the number of views (`view`) a note will receive based on its features. This can help content creators and platform administrators optimize their strategies for creating and promoting educational content.

### Data Source

The dataset was extracted directly from the Ask Mattrab database. It represents real-world user interactions and content metadata, making it a rich source for analysis and modeling.

# Loading & Cleaning the Data

The data are contained in notes_export.csv. Load the data.

```{r, message=FALSE}
notes <- read_csv("notes_export.csv")

glimpse(notes)
```

Removing the variables/features that are not very useful. These are thumbnail details, bodypdf details. creation details, last update details, etc.

```{r}

notes <- notes |>
  select(-id, -created_at, -updated_at, -image_file_name, - image_content_type, -image_file_size, -image_updated_at, -ecategory, -egrade, -chapter_id, -feedback, -verifier_id, -bodypdf_file_name, -bodypdf_content_type, -bodypdf_file_size, -bodypdf_updated_at, -topic_id)

#check the columns again
str(notes)
```

# Exploratory Data Analysis

Before diving into modeling, let's understand our data better:

```{r initial-viz}
# Visualize view distribution
ggplot(notes, aes(x = view)) +
  geom_histogram(fill = "steelblue", alpha = 0.7) +
  labs(title = "Distribution of Note Views",
       x = "Number of Views",
       y = "Count") +
  theme_minimal()

# View distribution by grade
ggplot(notes, aes(x = as.factor(grade_id), y = view)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "View Distribution by Grade",
       x = "Grade",
       y = "Number of Views") +
  theme_minimal()
```

**Key Observations:** 1. The view distribution is heavily right-skewed 2. We may need to consider log transformation 3. Different grades show varying view patterns

# Mutating Data

Let's mutate some data types and data values to make it friendly for the analysis. Also, let's replace any null values.

```{r}
# replacing the null cells
notes <- notes |>
  mutate(position = ifelse(is.na(position), "hidden", position), 
         grade_id = ifelse(is.na(grade_id), 12, grade_id), 
         subject_id = ifelse(is.na(subject_id), 1, subject_id),
  )

# mutating the types
notes <- notes |>
  mutate(
    title = nchar(title),
    user_id = as.factor(user_id),
    is_verified = as.factor(is_verified),
    status = factor(status, 
                    levels = c("draft", "published"),
                    ordered = TRUE),
    subject_id = as.factor(subject_id),
    grade_id = as.factor(grade_id),
    position = factor(position, 
                    levels = c("hidden", "shown"),
                    ordered = TRUE)
  )

colSums(is.na(notes)) 
```

# Data Splitting & Pre-processing

Let's split the data into training and test sets including 65% of records in the training set and stratifying the data by grade_id (because I'm interested to see which grade notes are getting more views.

```{r}
set.seed(427)

notes_split <- initial_split(notes, prop = 0.65, strata = grade_id)

notes_train <- training(notes_split)
notes_test  <- testing(notes_split)
```

## Recipies

Linear model recipes:

```{r cache=TRUE}

# Simple Mean and Mode Imputation
lm_recipe1 <- recipe(view ~ ., data = notes_train) |>
  # Mean (average) imputation for numeric features
  step_impute_mean(all_numeric_predictors()) |>
  # Mode (most repeated) imputation for categorical features
  step_impute_mode(all_nominal_predictors()) |>
  # Normalize numeric predictors
  step_normalize(all_numeric_predictors()) |>
  step_unknown(all_nominal(), -all_outcomes()) |>
  # Convert categorical variables to dummy variables
  step_dummy(all_nominal_predictors())

lm_recipe2 <- recipe(view ~ ., data = notes_train) |>
  # Median imputation
  step_impute_median(all_numeric_predictors()) |>
  # Lump rare categories into "Rare"
  step_other(all_nominal_predictors(), threshold = 0.05, other = "Rare") |>
  step_unknown(all_nominal(), -all_outcomes()) |>
  step_dummy(all_nominal(), -all_outcomes()) |>
  # Remove linear combinations of variables
  step_lincomb(all_predictors()) |>
  step_center(all_numeric_predictors()) |>
  # Standardize numeric variables
  step_scale(all_numeric_predictors())

# KNN Imputation
lm_recipe3 <- recipe(view ~ ., data = notes_train) |>
  step_nzv(all_predictors()) |>
  # KNN-based imputation
  step_impute_knn(all_numeric_predictors(), neighbors = 5) |>
  # Mode imputation for categorical features
  step_impute_mode(all_nominal_predictors()) |>
  step_unknown(all_nominal(), -all_outcomes()) |>
  # Convert categorical variables to dummy variables
  step_dummy(all_nominal_predictors()) |>
  # Remove collinear variables
  step_lincomb(all_predictors()) |>
  step_nzv(all_predictors()) |> 
  step_normalize(all_numeric_predictors())

```

Knn model recipes:

```{r}

knn_recipe1 <- recipe(view ~ ., data = notes_train) |>
  step_impute_knn(all_numeric_predictors(), neighbors = 5) |>
  step_impute_mode(all_nominal_predictors()) |>
  step_normalize(all_numeric_predictors()) |>
  step_unknown(all_nominal(), -all_outcomes()) |>
  step_dummy(all_nominal_predictors())

knn_recipe2 <- recipe(view ~ ., data = notes_train) |>
  step_impute_median(all_numeric_predictors()) |>
  step_other(all_nominal_predictors(), threshold = 0.05, other = "Rare") |>
  step_scale(all_numeric_predictors()) |>
  step_unknown(all_nominal(), -all_outcomes()) |>
  step_dummy(all_nominal_predictors())


knn_recipe3 <- recipe(view ~ ., data = notes_train) |>
  step_nzv(all_predictors()) |>
  step_impute_mean(all_numeric_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_other(all_nominal_predictors(), threshold = 0.01, other = "Rare") |>
  step_dummy(all_nominal_predictors(), one_hot = TRUE) |>
  step_corr(all_numeric_predictors(), threshold = 0.75) |>
  step_lincomb(all_numeric_predictors()) |>
  step_normalize(all_numeric_predictors())
  
```

# Model-Fitting & Evaluation

Lets create the `workflow_set` that contains 12 different workflows: 3 linear regression workflows, and 9 knn workflows.

```{r}
lm_model <- linear_reg() |>
  set_engine('lm')

knn5_model <- nearest_neighbor(neighbors = 5) |>
  set_engine("kknn") |>
  set_mode("regression")
knn10_model <- nearest_neighbor(neighbors = 10) |>
  set_engine("kknn") |>
  set_mode("regression")
knn50_model <- nearest_neighbor(neighbors = 50) |>
  set_engine("kknn") |>
  set_mode("regression")

lm_models <- list(
  lm_model = lm_model
)
knn_models <- list(
  knn5 = knn5_model,
  knn10 = knn10_model,
  knn50 = knn50_model
)

lm_preprocessors <- list(
  lm_knn_impute = lm_recipe3,
  lm_mean_impute = lm_recipe1,
  lm_median_imput = lm_recipe2
)
knn_preprocessors <- list(
  knn_knn_impute = knn_recipe1,
  knn_mean_impute = knn_recipe3,
  knn_median_imput = knn_recipe2
)

knn_models <- workflow_set(knn_preprocessors, knn_models, cross = TRUE)
lm_models <-  workflow_set(lm_preprocessors, lm_models, cross = TRUE)

all_models <- lm_models |> 
  bind_rows(knn_models)

notes_folds <- vfold_cv(notes_train, v = 5, repeats = 5)
notes_metrics <- metric_set(rmse, rsq)

all_fits <- all_models |> 
  workflow_map("fit_resamples",
               resamples = notes_folds,
               metrics = notes_metrics)

autoplot(all_fits,  metric = "rsq") + 
  geom_text_repel(aes(label = wflow_id))

autoplot(all_fits,  metric = "rmse") + 
  geom_text_repel(aes(label = wflow_id))
```

Looking at both rsq and rmse graph, **knn_knn_impute_knn50** appears to be the best model to predict the views count of my notes based on other features.

Let's re-fit the best model on the whole training set and estimate the error metrics on the test set.

```{r cache=TRUE}
best_workflow <- workflow() |>
  add_recipe(knn_recipe1) |>
  add_model(knn50_model)

best_fit <- best_workflow |>
  fit(data = notes_train)

predictions <- predict(best_fit, new_data = notes_test)

results <- notes_test |>
  bind_cols(predictions)

metrics <- metric_set(rmse, rsq)
error_metrics <- results |>
  metrics(truth = view, estimate = .pred)

error_metrics
```

# Model Interpretation

Since KNN is a non-parametric model, we'll use alternative approaches to understand feature relationships:

```{r model-interpretation}
# 1. Correlation analysis for numeric variables
numeric_vars <- notes_train %>%
  select_if(is.numeric)

cor_matrix <- cor(numeric_vars)
corrplot::corrplot(cor_matrix, 
                  method = "color",
                  type = "upper",
                  tl.col = "black",
                  title = "Correlation Between Numeric Features")

# 2. Box plots for categorical variables
important_cats <- c("status", "is_verified", "position")
plots <- lapply(important_cats, function(var) {
  ggplot(notes_train, aes_string(x = var, y = "view")) +
    geom_boxplot(fill = "lightblue") +
    theme_minimal() +
    labs(title = paste("View Distribution by", var))
})

# Display plots in a grid
gridExtra::grid.arrange(grobs = plots, ncol = 2)

# 3. Basic feature analysis
feature_summary <- notes_train %>%
  group_by(grade_id) %>%
  summarise(
    avg_views = mean(view),
    median_views = median(view),
    n_notes = n()
  ) %>%
  arrange(desc(avg_views))

knitr::kable(feature_summary, 
             caption = "View Statistics by Grade Level",
             digits = 2)
```

**Key Findings:**

1.  Content length (title/body) shows positive correlation with views.
2.  Verified notes tend to receive more views than unverified ones.
3.  Grade 11 content receives the highest average views.
4.  Published notes get significantly more views than drafts.

**Model Performance Analysis:**

1.  The R-squared value of 0.21 suggests that about 21% of the variance in views is explained by our features.
2.  Potential reasons for limited performance:
    1.  Non-linear relationships not fully captured.
    2.  Important external factors missing.
    3.  High variance in view counts.

# Limitations & Future Work

**Current Limitations:**

1.  Limited feature set due to privacy constraints
2.  External factors unknown

**Future Improvements:**

1.  Include time-based features.
2.  Collect content quality metrics.
3.  Consider seasonal patterns

The best **rsq** that I obtained is 0.2085752 which is not super good. Selecting only specific variables/features can make the model better. If you provide me an interview opportunity, I will tell you how. :)
